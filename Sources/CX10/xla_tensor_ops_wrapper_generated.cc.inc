// Autogenerated by codegen.py. Do not modify.

namespace swift_xla {
namespace ir {
namespace ops {
namespace {

class Cumprod : public Node {
 public:
  Cumprod(const Value& input, xla::int64 dim, c10::optional<at::ScalarType> dtype, bool exclusive, bool reverse)
      : Node(ir::OpKind(at::aten::cumprod),
             {input}, CumOpShapeFn(input, dim, dtype, exclusive, reverse),
             /*num_outputs=*/1, xla::util::MHash(dim, dtype, exclusive, reverse)),
        dim_(dim),
        dtype_(dtype),
        exclusive_(exclusive),
        reverse_(reverse) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Cumprod>(
        operands.at(0), dim_, dtype_, exclusive_, reverse_);
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerCumProd(
        loctx->GetOutputOp(operand(0)), dim_, dtype_, exclusive_, reverse_);
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    OpFieldToString(ss, "dim", dim_);
    OpFieldToString(ss, "dtype", dtype_);
    OpFieldToString(ss, "exclusive", exclusive_);
    OpFieldToString(ss, "reverse", reverse_);
    return ss.str();
  }

 private:
  xla::int64 dim_;
  c10::optional<at::ScalarType> dtype_;
  bool exclusive_;
  bool reverse_;
};

class Cumsum : public Node {
 public:
  Cumsum(const Value& input, xla::int64 dim, c10::optional<at::ScalarType> dtype, bool exclusive, bool reverse)
      : Node(ir::OpKind(at::aten::cumsum),
             {input}, CumOpShapeFn(input, dim, dtype, exclusive, reverse),
             /*num_outputs=*/1, xla::util::MHash(dim, dtype, exclusive, reverse)),
        dim_(dim),
        dtype_(dtype),
        exclusive_(exclusive),
        reverse_(reverse) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Cumsum>(
        operands.at(0), dim_, dtype_, exclusive_, reverse_);
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerCumSum(
        loctx->GetOutputOp(operand(0)), dim_, dtype_, exclusive_, reverse_);
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    OpFieldToString(ss, "dim", dim_);
    OpFieldToString(ss, "dtype", dtype_);
    OpFieldToString(ss, "exclusive", exclusive_);
    OpFieldToString(ss, "reverse", reverse_);
    return ss.str();
  }

 private:
  xla::int64 dim_;
  c10::optional<at::ScalarType> dtype_;
  bool exclusive_;
  bool reverse_;
};

class Eq : public Node {
 public:
  Eq(const Value& lhs, const Value& rhs)
      : Node(ir::OpKind(at::aten::eq),
             {lhs, rhs}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto lhs_ir = xla::Parameter(&b, 0, lhs.shape(), "p0");
       auto rhs_ir = xla::Parameter(&b, 1, rhs.shape(), "p1");
       xla::XlaOp result = LowerBinaryOp<xla::Eq>(
         lhs_ir, rhs_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Eq>(
        operands.at(0), operands.at(1));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerBinaryOp<xla::Eq>(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class Ge : public Node {
 public:
  Ge(const Value& lhs, const Value& rhs)
      : Node(ir::OpKind(at::aten::ge),
             {lhs, rhs}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto lhs_ir = xla::Parameter(&b, 0, lhs.shape(), "p0");
       auto rhs_ir = xla::Parameter(&b, 1, rhs.shape(), "p1");
       xla::XlaOp result = LowerBinaryOp<xla::Ge>(
         lhs_ir, rhs_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Ge>(
        operands.at(0), operands.at(1));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerBinaryOp<xla::Ge>(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class Gt : public Node {
 public:
  Gt(const Value& lhs, const Value& rhs)
      : Node(ir::OpKind(at::aten::gt),
             {lhs, rhs}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto lhs_ir = xla::Parameter(&b, 0, lhs.shape(), "p0");
       auto rhs_ir = xla::Parameter(&b, 1, rhs.shape(), "p1");
       xla::XlaOp result = LowerBinaryOp<xla::Gt>(
         lhs_ir, rhs_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Gt>(
        operands.at(0), operands.at(1));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerBinaryOp<xla::Gt>(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class Le : public Node {
 public:
  Le(const Value& lhs, const Value& rhs)
      : Node(ir::OpKind(at::aten::le),
             {lhs, rhs}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto lhs_ir = xla::Parameter(&b, 0, lhs.shape(), "p0");
       auto rhs_ir = xla::Parameter(&b, 1, rhs.shape(), "p1");
       xla::XlaOp result = LowerBinaryOp<xla::Le>(
         lhs_ir, rhs_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Le>(
        operands.at(0), operands.at(1));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerBinaryOp<xla::Le>(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class LogSoftmaxBackward : public Node {
 public:
  LogSoftmaxBackward(const Value& grad_output, const Value& output, xla::int64 dim)
      : Node(ir::OpKind(at::aten::_log_softmax_backward_data),
             {grad_output, output}, grad_output.shape(),
             /*num_outputs=*/1, xla::util::MHash(dim)),
        dim_(dim) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<LogSoftmaxBackward>(
        operands.at(0), operands.at(1), dim_);
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = BuildLogSoftmaxGrad(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)), dim_);
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    OpFieldToString(ss, "dim", dim_);
    return ss.str();
  }

 private:
  xla::int64 dim_;
};

class Lt : public Node {
 public:
  Lt(const Value& lhs, const Value& rhs)
      : Node(ir::OpKind(at::aten::lt),
             {lhs, rhs}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto lhs_ir = xla::Parameter(&b, 0, lhs.shape(), "p0");
       auto rhs_ir = xla::Parameter(&b, 1, rhs.shape(), "p1");
       xla::XlaOp result = LowerBinaryOp<xla::Lt>(
         lhs_ir, rhs_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Lt>(
        operands.at(0), operands.at(1));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerBinaryOp<xla::Lt>(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class Ne : public Node {
 public:
  Ne(const Value& lhs, const Value& rhs)
      : Node(ir::OpKind(at::aten::ne),
             {lhs, rhs}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto lhs_ir = xla::Parameter(&b, 0, lhs.shape(), "p0");
       auto rhs_ir = xla::Parameter(&b, 1, rhs.shape(), "p1");
       xla::XlaOp result = LowerBinaryOp<xla::Ne>(
         lhs_ir, rhs_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Ne>(
        operands.at(0), operands.at(1));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerBinaryOp<xla::Ne>(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class Pow : public Node {
 public:
  Pow(const Value& input, const Value& other)
      : Node(ir::OpKind(at::aten::pow),
             {input, other}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto input_ir = xla::Parameter(&b, 0, input.shape(), "p0");
       auto other_ir = xla::Parameter(&b, 1, other.shape(), "p1");
       xla::XlaOp result = xla::Pow(
         input_ir, other_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Pow>(
        operands.at(0), operands.at(1));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = xla::Pow(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class Relu : public Node {
 public:
  Relu(const Value& input)
      : Node(ir::OpKind(at::aten::relu),
             {input}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto input_ir = xla::Parameter(&b, 0, input.shape(), "p0");
       xla::XlaOp result = BuildRelu(
         input_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Relu>(
        operands.at(0));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = BuildRelu(
        loctx->GetOutputOp(operand(0)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class Rem : public Node {
 public:
  Rem(const Value& input, const Value& other)
      : Node(ir::OpKind(at::aten::xla_rem),
             {input, other}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto input_ir = xla::Parameter(&b, 0, input.shape(), "p0");
       auto other_ir = xla::Parameter(&b, 1, other.shape(), "p1");
       xla::XlaOp result = xla::Rem(
         input_ir, other_ir);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash()) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Rem>(
        operands.at(0), operands.at(1));
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = xla::Rem(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)));
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    return ss.str();
  }

 private:
};

class Squeeze : public Node {
 public:
  Squeeze(const Value& input, xla::int64 dim)
      : Node(ir::OpKind(at::aten::squeeze),
             {input}, [&]() {
       xla::XlaBuilder b("InferOutputShape");
       auto input_ir = xla::Parameter(&b, 0, input.shape(), "p0");
       xla::XlaOp result = LowerSqueeze(
         input_ir, dim);
       return XlaHelpers::ShapeOfXlaOp(result);
     },
             /*num_outputs=*/1, xla::util::MHash(dim)),
        dim_(dim) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Squeeze>(
        operands.at(0), dim_);
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = LowerSqueeze(
        loctx->GetOutputOp(operand(0)), dim_);
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    OpFieldToString(ss, "dim", dim_);
    return ss.str();
  }

 private:
  xla::int64 dim_;
};

class Threshold : public Node {
 public:
  Threshold(const Value& input, const Value& output, float threshold, float value)
      : Node(ir::OpKind(at::aten::threshold_backward),
             {input, output}, input.shape(),
             /*num_outputs=*/1, xla::util::MHash(threshold, value)),
        threshold_(threshold),
        value_(value) {}

  NodePtr Clone(OpList operands) const override {
    return MakeNode<Threshold>(
        operands.at(0), operands.at(1), threshold_, value_);
  }

  XlaOpVector Lower(LoweringContext* loctx) const override {
    xla::XlaOp result = BuildThreshold(
        loctx->GetOutputOp(operand(0)), loctx->GetOutputOp(operand(1)), threshold_, value_);
    return ReturnOp(result, loctx);
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << Node::ToString();
    OpFieldToString(ss, "threshold", threshold_);
    OpFieldToString(ss, "value", value_);
    return ss.str();
  }

 private:
  float threshold_;
  float value_;
};

}  // namespace
}  // namespace ops
}  // namespace ir
}  // namespace swift_xla

OpaqueXLATensor* XLATensor_cumprod(OpaqueXLATensor* input, int64_t dim, Optional_XLAScalarType dtype, bool exclusive, bool reverse) {
  auto input_ir_value = input->GetIrValue();
   return new swift_xla::XLATensor(input->CreateFrom(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Cumprod>(input_ir_value, swift_xla::XlaHelpers::GetCanonicalDimensionIndex(dim, input_ir_value.shape().rank()), dtype.value(), exclusive, reverse)));
}

OpaqueXLATensor* XLATensor_cumsum(OpaqueXLATensor* input, int64_t dim, Optional_XLAScalarType dtype, bool exclusive, bool reverse) {
  auto input_ir_value = input->GetIrValue();
   return new swift_xla::XLATensor(input->CreateFrom(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Cumsum>(input_ir_value, swift_xla::XlaHelpers::GetCanonicalDimensionIndex(dim, input_ir_value.shape().rank()), dtype.value(), exclusive, reverse)));
}

OpaqueXLATensor* XLATensor_eq(OpaqueXLATensor* lhs, OpaqueXLATensor* rhs) {
  auto lhs_ir_value = lhs->GetIrValue();
  auto rhs_ir_value = rhs->GetIrValue();
   return new swift_xla::XLATensor(swift_xla::XLATensor::Create(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Eq>(lhs_ir_value, rhs_ir_value),
      lhs->GetDevice(),
      at::ScalarType::Bool));
}

OpaqueXLATensor* XLATensor_ge(OpaqueXLATensor* lhs, OpaqueXLATensor* rhs) {
  auto lhs_ir_value = lhs->GetIrValue();
  auto rhs_ir_value = rhs->GetIrValue();
   return new swift_xla::XLATensor(swift_xla::XLATensor::Create(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Ge>(lhs_ir_value, rhs_ir_value),
      lhs->GetDevice(),
      at::ScalarType::Bool));
}

OpaqueXLATensor* XLATensor_gt(OpaqueXLATensor* lhs, OpaqueXLATensor* rhs) {
  auto lhs_ir_value = lhs->GetIrValue();
  auto rhs_ir_value = rhs->GetIrValue();
   return new swift_xla::XLATensor(swift_xla::XLATensor::Create(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Gt>(lhs_ir_value, rhs_ir_value),
      lhs->GetDevice(),
      at::ScalarType::Bool));
}

OpaqueXLATensor* XLATensor_le(OpaqueXLATensor* lhs, OpaqueXLATensor* rhs) {
  auto lhs_ir_value = lhs->GetIrValue();
  auto rhs_ir_value = rhs->GetIrValue();
   return new swift_xla::XLATensor(swift_xla::XLATensor::Create(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Le>(lhs_ir_value, rhs_ir_value),
      lhs->GetDevice(),
      at::ScalarType::Bool));
}

OpaqueXLATensor* XLATensor_log_softmax_backward(OpaqueXLATensor* grad_output, OpaqueXLATensor* output, int64_t dim) {
  auto grad_output_ir_value = grad_output->GetIrValue();
  auto output_ir_value = output->GetIrValue();
   return new swift_xla::XLATensor(grad_output->CreateFrom(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::LogSoftmaxBackward>(grad_output_ir_value, output_ir_value, swift_xla::XlaHelpers::GetCanonicalDimensionIndex(dim, grad_output_ir_value.shape().rank()))));
}

OpaqueXLATensor* XLATensor_lt(OpaqueXLATensor* lhs, OpaqueXLATensor* rhs) {
  auto lhs_ir_value = lhs->GetIrValue();
  auto rhs_ir_value = rhs->GetIrValue();
   return new swift_xla::XLATensor(swift_xla::XLATensor::Create(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Lt>(lhs_ir_value, rhs_ir_value),
      lhs->GetDevice(),
      at::ScalarType::Bool));
}

OpaqueXLATensor* XLATensor_ne(OpaqueXLATensor* lhs, OpaqueXLATensor* rhs) {
  auto lhs_ir_value = lhs->GetIrValue();
  auto rhs_ir_value = rhs->GetIrValue();
   return new swift_xla::XLATensor(swift_xla::XLATensor::Create(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Ne>(lhs_ir_value, rhs_ir_value),
      lhs->GetDevice(),
      at::ScalarType::Bool));
}

OpaqueXLATensor* XLATensor_pow(OpaqueXLATensor* input, OpaqueXLATensor* other) {
  auto input_ir_value = input->GetIrValue();
  auto other_ir_value = other->GetIrValue();
   return new swift_xla::XLATensor(input->CreateFrom(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Pow>(input_ir_value, other_ir_value)));
}

OpaqueXLATensor* XLATensor_relu(OpaqueXLATensor* input) {
  auto input_ir_value = input->GetIrValue();
   return new swift_xla::XLATensor(input->CreateFrom(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Relu>(input_ir_value)));
}

OpaqueXLATensor* XLATensor_rem(OpaqueXLATensor* input, OpaqueXLATensor* other) {
  auto input_ir_value = input->GetIrValue();
  auto other_ir_value = other->GetIrValue();
   return new swift_xla::XLATensor(input->CreateFrom(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Rem>(input_ir_value, other_ir_value)));
}

OpaqueXLATensor* XLATensor_squeeze(OpaqueXLATensor* input, int64_t dim) {
  auto input_ir_value = input->GetIrValue();
   return new swift_xla::XLATensor(input->CreateFrom(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Squeeze>(input_ir_value, swift_xla::XlaHelpers::GetCanonicalDimensionIndex(dim, input_ir_value.shape().rank()))));
}

OpaqueXLATensor* XLATensor_threshold(OpaqueXLATensor* input, OpaqueXLATensor* output, float threshold, float value) {
  auto input_ir_value = input->GetIrValue();
  auto output_ir_value = output->GetIrValue();
   return new swift_xla::XLATensor(input->CreateFrom(
      swift_xla::ir::MakeNode<swift_xla::ir::ops::Threshold>(input_ir_value, output_ir_value, threshold, value)));
}
