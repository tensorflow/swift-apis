// Copyright 2019 The TensorFlow Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import XCTest

@testable import TensorFlow

final class SequentialTests: XCTestCase {
  func testSequential() {
    struct Model: Layer {
      var dense1 = Dense<Float>(
        inputSize: 2,
        outputSize: 4,
        activation: relu,
        weightInitializer: glorotUniform(seed: (0xfffffff, 0xfeeff)))
      var dense2 = Dense<Float>(
        inputSize: 4,
        outputSize: 1,
        activation: relu,
        weightInitializer: glorotUniform(seed: (0xeffeffe, 0xfffe)))

      @differentiable
      func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {
        return input.sequenced(through: dense1, dense2)
      }
    }
    var model = Model()
    let sgd = SGD(for: model, learningRate: 0.02)
    let rmsprop = RMSProp(for: model, learningRate: 0.02)
    let adam = Adam(for: model, learningRate: 0.02)
    let adamax = AdaMax(for: model, learningRate: 0.02)
    let amsgrad = AMSGrad(for: model, learningRate: 0.02)
    let adagrad = AdaGrad(for: model, learningRate: 0.02)
    let adadelta = AdaDelta(for: model, learningRate: 0.02)
    let radam = RAdam(for: model, learningRate: 0.02)
    let x: Tensor<Float> = [[0, 0], [0, 1], [1, 0], [1, 1]]
    let y: Tensor<Float> = [0, 1, 1, 0]
    Context.local.learningPhase = .training
    withTensorLeakChecking {
      for _ in 0..<1000 {
        let ùõÅmodel = gradient(at: model) { model -> Tensor<Float> in
          let ≈∑ = model(x)
          return meanSquaredError(predicted: ≈∑, expected: y)
        }
        sgd.update(&model, along: ùõÅmodel)
        rmsprop.update(&model, along: ùõÅmodel)
        adam.update(&model, along: ùõÅmodel)
        adamax.update(&model, along: ùõÅmodel)
        amsgrad.update(&model, along: ùõÅmodel)
        adagrad.update(&model, along: ùõÅmodel)
        adadelta.update(&model, along: ùõÅmodel)
        radam.update(&model, along: ùõÅmodel)
      }
    }
    XCTAssertEqual(
      model.inferring(from: [[0, 0], [0, 1], [1, 0], [1, 1]]),
      [[0.50378805], [0.50378805], [0.50378805], [0.50378805]])
  }

  static var allTests = [
    ("testSequential", testSequential)
  ]
}
